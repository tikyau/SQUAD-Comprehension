{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from nltk.parse import stanford\n",
    "import nltk\n",
    "import json\n",
    "from nltk.tag.stanford import StanfordPOSTagger as POS_Tag\n",
    "\n",
    "_path_to_model = '/home/shanu/nltk/jars/english-bidirectional-distsim.tagger' \n",
    "_path_to_jar = '/home/shanu/nltk/jars/stanford-postagger.jar'\n",
    "\n",
    "st = POS_Tag(_path_to_model, _path_to_jar)\n",
    "\n",
    "from nltk.tag import StanfordNERTagger as NER_Tag\n",
    "\n",
    "NER_st = NER_Tag('/home/shanu/nltk/jars/english.all.3class.distsim.crf.ser.gz',\n",
    "               '/home/shanu/nltk/jars/stanford-ner.jar') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"data/squad/shared_dev.json\") as f1:\n",
    "    data_dev = json.load(f1)\n",
    "\n",
    "with open(\"data/squad/shared_test.json\") as f2:\n",
    "    data_test = json.load(f2)\n",
    "\n",
    "with open(\"data/squad/shared_train.json\") as f3:\n",
    "    data_train = json.load(f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "POS_dev = []\n",
    "for i in range(len(data_dev['x'])):\n",
    "    sents = []\n",
    "    for l in range(len(data_dev['x'][i])):\n",
    "        sents.append(0)\n",
    "    POS_dev.append(sents)\n",
    "\n",
    "POS_train = []\n",
    "for i in range(len(data_train['x'])):\n",
    "    sents = []\n",
    "    for l in range(len(data_train['x'][i])):\n",
    "        sents.append(0)\n",
    "    POS_train.append(sents)\n",
    "    \n",
    "POS_test = []\n",
    "for i in range(len(data_test['x'])):\n",
    "    sents = []\n",
    "    for l in range(len(data_test['x'][i])):\n",
    "        sents.append(0)\n",
    "    POS_test.append(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dev['x'][1][30][0][203] = '397'\n",
    "data_dev['x'][1][30][0][214] = '452'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dev['x'][1][35][0][137] = '178'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train['x'][5][0][0][13] = 'u200b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train['x'][6][1][0][152] = '141'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train['x'][6][52][0][47] = 'two'\n",
    "data_train['x'][6][52][0][198] = 'abbot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 102\n",
    "l = 84\n",
    "\n",
    "data_train['x'][k][l][0][62] = 'c'\n",
    "data_train['x'][k][l][0][61] = 'd'\n",
    "data_train['x'][k][l][0][149] = 'd'\n",
    "data_train['x'][k][l][0][147] = 'Taylor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 108\n",
    "l = 6\n",
    "\n",
    "for i in range(len(data_train['x'][k][l][0])):\n",
    "    if(data_train['x'][k][l][0][i]=='–'):\n",
    "        data_train['x'][k][l][0][i] = '-'\n",
    "\n",
    "data_train['x'][k][l][0][215] = 'Maymun'\n",
    "data_train['x'][k][l][0][211] = 'Allah'\n",
    "\n",
    "data_train['x'][k][l][0][206] = 'Qaddah'\n",
    "data_train['x'][k][l][0][204] = 'ul'\n",
    "data_train['x'][k][l][0][200] = 'Maymun'\n",
    "data_train['x'][k][l][0][181] = 'Natiqs'\n",
    "\n",
    "data_train['x'][k][l][0][183] = 'Samads'\n",
    "data_train['x'][k][l][0][191] = 'Isma'\n",
    "data_train['x'][k][l][0][195] = 'il'\n",
    "data_train['x'][k][l][0][198] = 'saghir'\n",
    "\n",
    "data_train['x'][k][l][0][167] = 'Allah'\n",
    "data_train['x'][k][l][0][172] = 'Talib'\n",
    "data_train['x'][k][l][0][131] = 'Samad'\n",
    "data_train['x'][k][l][0][133] = '\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 115\n",
    "l = 63\n",
    "\n",
    "data_train['x'][k][l][0][192] = 'carrot'\n",
    "data_train['x'][k][l][0][196] = 'snake'\n",
    "data_train['x'][k][l][0][205] = 'snake'\n",
    "data_train['x'][k][l][0][228] = 'mountain'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 256\n",
    "l = 3\n",
    "data_train['x'][k][l][0][102] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 375\n",
    "l = 29\n",
    "\n",
    "data_train['x'][k][l][0][310] = ''\n",
    "data_train['x'][k][l][0][161] = 'd'\n",
    "data_train['x'][k][l][0][165] = 'a'\n",
    "data_train['x'][k][l][0][255] = 'd'\n",
    "data_train['x'][k][l][0][308] = 'd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 377\n",
    "l = 0\n",
    "\n",
    "data_train['x'][k][l][0][69] = '3794'\n",
    "data_train['x'][k][l][0][78] ='9826'\n",
    "data_train['x'][k][l][0][81] = '3794'\n",
    "data_train['x'][k][l][0][100] = '9826'\n",
    "\n",
    "data_train['x'][k][l][0][103] = '3794'\n",
    "data_train['x'][k][l][0][114] = '9629'\n",
    "\n",
    "data_train['x'][k][l][0][117] = '3717'\n",
    "data_train['x'][k][l][0][127] = '9522'\n",
    "data_train['x'][k][l][0][130] = '3676'\n",
    "\n",
    "data_train['x'][k][l][0][14] = '9372'\n",
    "data_train['x'][k][l][0][17] = '3618'\n",
    "data_train['x'][k][l][0][35] = '9629'\n",
    "data_train['x'][k][l][0][38] = '3717'\n",
    "\n",
    "data_train['x'][k][l][0][55] = '9631'\n",
    "data_train['x'][k][l][0][58] = '3718'\n",
    "data_train['x'][k][l][0][66] = '9631'\n",
    "data_train['x'][k][l][0][70] = 'square'\n",
    "\n",
    "for i in range(len(data_train['x'][k][l][0])):\n",
    "    if(data_train['x'][k][l][0][i]=='sq'):\n",
    "        data_train['x'][k][l][0][i] = 'square'\n",
    "    elif(data_train['x'][k][l][0][i] == 'mi'):\n",
    "        data_train['x'][k][l][0][i] = 'mile'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 400\n",
    "l = 0\n",
    "\n",
    "data_train['x'][k][l][0][153] = '1648'\n",
    "data_train['x'][k][l][0][156] = '6363'\n",
    "data_train['x'][k][l][0][157] = 'square'\n",
    "data_train['x'][k][l][0][158] = 'mile'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 1\n",
    "l = 35\n",
    "\n",
    "data_dev['x'][k][l][0][133] = 'Krolikarnia'\n",
    "\n",
    "for i in range(len(data_dev['x'][k][l][0])):\n",
    "    if(data_dev['x'][k][l][0][i] == '–'):\n",
    "        data_dev['x'][k][l][0][i] = '-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 26\n",
    "l = 5\n",
    "\n",
    "for i in range(len(data_dev['x'][k][l][0])):\n",
    "    if(data_dev['x'][k][l][0][i] == '–'):\n",
    "        data_dev['x'][k][l][0][i] = '-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 26\n",
    "l = 5\n",
    "\n",
    "for i in range(len(data_test['x'][k][l][0])):\n",
    "    if(data_test['x'][k][l][0][i] == '–'):\n",
    "        data_test['x'][k][l][0][i] = '-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 1\n",
    "l = 30\n",
    "\n",
    "for i in range(len(data_test['x'][k][l][0])):\n",
    "    if(data_test['x'][k][l][0][i] == '–'):\n",
    "        data_test['x'][k][l][0][i] = '-'\n",
    "\n",
    "data_test['x'][k][l][0][208] = 'Szczesliwice'\n",
    "data_test['x'][k][l][0][206] = ''\n",
    "data_test['x'][k][l][0][214] = '452'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 1\n",
    "l = 35\n",
    "\n",
    "for i in range(len(data_test['x'][k][l][0])):\n",
    "    if(data_test['x'][k][l][0][i] == '–'):\n",
    "        data_test['x'][k][l][0][i] = '-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k in range(len(data_dev['x'])):\n",
    "    for l in range(len(data_dev['x'][k])):\n",
    "        text = data_dev['x'][k][l][0]\n",
    "        try:\n",
    "            tags = st.tag(text)\n",
    "            pos = []\n",
    "            j = 0\n",
    "            for i in range(len(text)):\n",
    "                if(text[i]==''):\n",
    "                    pos.append('')\n",
    "                else:\n",
    "                    try:\n",
    "                        pos.append(tags[j][1])\n",
    "                        j +=1\n",
    "                    except IndexError:\n",
    "                        print(\"Index Errorrr:\", k,l)\n",
    "            POS_dev[k][l] = pos\n",
    "            print(\"PASS\", k,l)\n",
    "            \n",
    "        except OSError:\n",
    "            print(\"Errorrr:\", k,l)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('pos_x_dev.json', 'w') as f:\n",
    "    json.dump(POS_dev, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k in range(len(data_train['x'])):\n",
    "    for l in range(len(data_train['x'][k])):\n",
    "        text = data_train['x'][k][l][0]\n",
    "        try:\n",
    "            tags = st.tag(text)\n",
    "            pos = []\n",
    "            j = 0\n",
    "            for i in range(len(text)):\n",
    "                if(text[i]==''):\n",
    "                    pos.append('')\n",
    "                else:\n",
    "                    try:\n",
    "                        pos.append(tags[j][1])\n",
    "                        j +=1\n",
    "                    except IndexError:\n",
    "                        print(\"Index Errorrr:\", k,l)\n",
    "            POS_train[k][l] = pos\n",
    "            print(\"PASS\", k,l)\n",
    "            \n",
    "        except OSError:\n",
    "            print(\"Errorrr:\", k,l)\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('pos_x_train.json', 'w') as f:\n",
    "    json.dump(POS_train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k in range(len(data_test['x'])):\n",
    "    for l in range(len(data_test['x'][k])):\n",
    "        text = data_test['x'][k][l][0]\n",
    "        try:\n",
    "            tags = st.tag(text)\n",
    "            pos = []\n",
    "            j = 0\n",
    "            for i in range(len(text)):\n",
    "                if(text[i]==''):\n",
    "                    pos.append('')\n",
    "                else:\n",
    "                    try:\n",
    "                        pos.append(tags[j][1])\n",
    "                        j +=1\n",
    "                    except IndexError:\n",
    "                        print(\"Index Errorrr:\", k,l)\n",
    "            POS_test[k][l] = pos\n",
    "            print(\"PASS\", k,l)\n",
    "            \n",
    "        except OSError:\n",
    "            print(\"Errorrr:\", k,l)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('pos_x_test.json', 'w') as f:\n",
    "    json.dump(POS_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NER_train = []\n",
    "for i in range(len(data_train['x'])):\n",
    "    sents = []\n",
    "    for l in range(len(data_train['x'][i])):\n",
    "        sents.append(0)\n",
    "    NER_train.append(sents)\n",
    "    \n",
    "NER_test = []\n",
    "for i in range(len(data_test['x'])):\n",
    "    sents = []\n",
    "    for l in range(len(data_test['x'][i])):\n",
    "        sents.append(0)\n",
    "    NER_test.append(sents)\n",
    "    \n",
    "NER_dev = []\n",
    "for i in range(len(data_dev['x'])):\n",
    "    sents = []\n",
    "    for l in range(len(data_dev['x'][i])):\n",
    "        sents.append(0)\n",
    "    NER_dev.append(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k in range(len(data_train['x'])):\n",
    "    for l in range(len(data_train['x'][k])):\n",
    "        text = data_train['x'][k][l][0]\n",
    "        try:\n",
    "            tags = NER_st.tag(text)\n",
    "            ner = []\n",
    "            j = 0\n",
    "            for i in range(len(text)):\n",
    "                if(text[i]==''):\n",
    "                    ner.append('')\n",
    "                else:\n",
    "                    try:\n",
    "                        ner.append(tags[j][1])\n",
    "                        j +=1\n",
    "                    except IndexError:\n",
    "                        print(\"Index Errorrr:\", k,l)\n",
    "                    \n",
    "            NER_train[k][l] = ner\n",
    "            print(\"PASS\", k,l)\n",
    "            \n",
    "        except OSError:\n",
    "            print(\"Errorrr:\", k,l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('ner_x_train.json', 'w') as f:\n",
    "    json.dump(NER_train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k in range(len(data_test['x'])):\n",
    "    for l in range(len(data_test['x'][k])):\n",
    "        text = data_test['x'][k][l][0]\n",
    "        try:\n",
    "            tags = NER_st.tag(text)\n",
    "            ner = []\n",
    "            j = 0\n",
    "            for i in range(len(text)):\n",
    "                if(text[i]==''):\n",
    "                    ner.append('')\n",
    "                else:\n",
    "                    try:\n",
    "                        ner.append(tags[j][1])\n",
    "                        j +=1\n",
    "                    except IndexError:\n",
    "                        print(\"Index Errorrr:\", k,l)\n",
    "            NER_test[k][l] = ner\n",
    "            print(\"PASS\", k,l)\n",
    "            \n",
    "        except OSError:\n",
    "            print(\"Errorrr:\", k,l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('ner_x_test.json', 'w') as f:\n",
    "    json.dump(NER_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k in range(len(data_dev['x'])):\n",
    "    for l in range(len(data_dev['x'][k])):\n",
    "        text = data_dev['x'][k][l][0]\n",
    "        try:\n",
    "            tags = NER_st.tag(text)\n",
    "            ner = []\n",
    "            j = 0\n",
    "            for i in range(len(text)):\n",
    "                if(text[i]==''):\n",
    "                    ner.append('')\n",
    "                else:\n",
    "                    try:\n",
    "                        ner.append(tags[j][1])\n",
    "                        j +=1\n",
    "                    except IndexError:\n",
    "                        print(\"Index Errorrr:\", k,l)\n",
    "            NER_dev[k][l] = ner\n",
    "            print(\"PASS\", k,l)\n",
    "            \n",
    "        except OSError:\n",
    "            print(\"Errorrr:\", k,l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('ner_x_dev.json', 'w') as f:\n",
    "    json.dump(NER_dev, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
